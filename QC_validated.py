"""
QC Validated Dataset Generator
================================
This script creates a validated dataset by reading the QC results from qc_variables.py
and filtering/organizing the data based on QC flags.

Author: Benedetta Torelli
Date: November 6, 2025
Version: 1.0

Input:  seaexplorer_qc_variables.csv (output from qc_variables.py)
Output: QC_validated.csv (validated dataset with TIME as reference)
"""

import pandas as pd
import numpy as np
import logging
import os
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
_log = logging.getLogger(__name__)


def aggregate_qc_flags(row, qc_columns):
    """
    Aggregate multiple QC flags into a single flag following priority rules.
    
    Priority rules:
    1. If any flag is 4 (BAD) -> return 4
    2. If any flag is 9 (MISSING) and no 4 present:
       - If others are all 1 (GOOD) -> return 1
       - If any 4 present -> return 4
    3. If any flag is 0 (NOT_EVALUATED) and all others are 1 (GOOD) -> ignore 0, return 1
    4. If all flags are 1 (GOOD) -> return 1
    
    Args:
        row: DataFrame row
        qc_columns: List of QC column names to aggregate
        
    Returns:
        Aggregated QC flag (1, 4, or 9)
    """
    # Get all flags for this row
    flags = [row[col] for col in qc_columns]
    
    # Convert to set for easier checking (excluding NaN if any)
    flag_set = set([f for f in flags if pd.notna(f)])
    
    # Rule 1: If any flag is 4 (BAD), return 4
    if 4 in flag_set:
        return 4
    
    # Rule 2: Check for 9 (MISSING)
    if 9 in flag_set:
        # Remove 9 and 0 to check remaining flags
        remaining = flag_set - {9, 0}
        if len(remaining) == 0 or remaining == {1}:
            # All other flags are 1 or don't exist
            return 1
        else:
            # Should not happen based on rules, but safety check
            return 9
    
    # Rule 3 & 4: Check for 0 (NOT_EVALUATED) or all 1 (GOOD)
    if flag_set == {1} or flag_set == {1, 0} or flag_set == {0}:
        return 1
    
    # If only 0 present or empty, return 1 (default good)
    if len(flag_set) == 0:
        return 1
    
    # Default case (should not reach here normally)
    return 1
    """
    Aggregate multiple QC flags into a single flag following priority rules.
    
    Priority rules:
    1. If any flag is 4 (BAD) -> return 4
    2. If any flag is 9 (MISSING) and no 4 present:
       - If others are all 1 (GOOD) -> return 1
       - If any 4 present -> return 4
    3. If any flag is 0 (NOT_EVALUATED) and all others are 1 (GOOD) -> ignore 0, return 1
    4. If all flags are 1 (GOOD) -> return 1
    
    Args:
        row: DataFrame row
        qc_columns: List of QC column names to aggregate
        
    Returns:
        Aggregated QC flag (1, 4, or 9)
    """
    # Get all flags for this row
    flags = [row[col] for col in qc_columns]
    
    # Convert to set for easier checking (excluding NaN if any)
    flag_set = set([f for f in flags if pd.notna(f)])
    
    # Rule 1: If any flag is 4 (BAD), return 4
    if 4 in flag_set:
        return 4
    
    # Rule 2: Check for 9 (MISSING)
    if 9 in flag_set:
        # Remove 9 and 0 to check remaining flags
        remaining = flag_set - {9, 0}
        if len(remaining) == 0 or remaining == {1}:
            # All other flags are 1 or don't exist
            return 1
        else:
            # Should not happen based on rules, but safety check
            return 9
    
    # Rule 3 & 4: Check for 0 (NOT_EVALUATED) or all 1 (GOOD)
    if flag_set == {1} or flag_set == {1, 0} or flag_set == {0}:
        return 1
    
    # If only 0 present or empty, return 1 (default good)
    if len(flag_set) == 0:
        return 1
    
    # Default case (should not reach here normally)
    return 1


def load_qc_csv(input_path: str) -> pd.DataFrame:
    """Load the QC variables CSV file generated by qc_variables.py.
    
    Args:
        input_path: Path to the seaexplorer_qc_variables.csv file
        
    Returns:
        DataFrame with all QC data
    """
    _log.info(f"Loading QC CSV from: {input_path}")
    
    # Read CSV, treating 'null' as NaN for internal processing
    df = pd.read_csv(input_path, na_values=['null', 'NULL', ''])
    
    _log.info(f"Loaded {len(df)} rows and {len(df.columns)} columns")
    _log.info(f"Columns: {list(df.columns[:10])}...")  # Show first 10 columns
    
    return df


def create_validated_dataset(df_qc):
    """
    Create validated dataset with scientific data and QC flags alternated.
    
    Args:
        df_qc: DataFrame from qc_variables.py output
        
    Returns:
        DataFrame with validated columns (data + QC flags)
    """
    _log.info("Creating validated dataset...")
    
    # Step 1: Extract TIME column as reference
    validated_df = pd.DataFrame()
    validated_df['TIME'] = df_qc['TIME']
    
    _log.info(f"Added TIME column with {len(validated_df)} timestamps")
    _log.info(f"Time range: {validated_df['TIME'].min()} to {validated_df['TIME'].max()}")
    
    # Step 2: Add DATE_QC
    validated_df['DATE_QC'] = df_qc['Date_QC']
    
    _log.info(f"Added DATE_QC column - Flag distribution:")
    _log.info(f"  {validated_df['DATE_QC'].value_counts().to_dict()}")
    
    # Step 3: Add LATITUDE, LONGITUDE, LOCATION_QC
    validated_df['LATITUDE'] = df_qc['LATITUDE']
    validated_df['LONGITUDE'] = df_qc['LONGITUDE']
    validated_df['LOCATION_QC'] = df_qc['Location_QC']
    
    _log.info(f"Added LATITUDE, LONGITUDE columns")
    _log.info(f"Added LOCATION_QC column - Flag distribution:")
    _log.info(f"  {validated_df['LOCATION_QC'].value_counts().to_dict()}")
    
    # Step 5: Add TEMP + TEMP_QC (aggregated)
    validated_df['TEMP'] = df_qc['TEMP']
    _log.info("Aggregating TEMP QC flags...")
    temp_qc_columns = [
        'TEMP_Range_QC',
        'TEMP_Na_QC', 
        'TEMP_Sensor_QC',
        'TEMP_Spike_QC',
        'TEMP_Density_QC',
        'TEMP_Stuck_QC'
    ]
    
    # Apply aggregation function
    validated_df['TEMP_QC'] = df_qc.apply(
        lambda row: aggregate_qc_flags(row, temp_qc_columns),
        axis=1
    )
    
    _log.info(f"Added TEMP + TEMP_QC - Flag distribution:")
    _log.info(f"  {validated_df['TEMP_QC'].value_counts().to_dict()}")
    
    # Step 5: Add CNDC + CNDC_QC (aggregated)
    validated_df['CNDC'] = df_qc['CNDC']
    _log.info("Aggregating CNDC QC flags...")
    cndc_qc_columns = [
        'CNDC_Range_QC',
        'CNDC_Na_QC',
        'CNDC_Sensor_QC',
        'CNDC_Stuck_QC'
    ]
    
    # Apply aggregation function (vectorized)
    validated_df['CNDC_QC'] = df_qc.apply(
        lambda row: aggregate_qc_flags(row, cndc_qc_columns),
        axis=1
    )
    
    _log.info(f"Added CNDC + CNDC_QC - Flag distribution:")
    _log.info(f"  {validated_df['CNDC_QC'].value_counts().to_dict()}")
    
    # Step 6: Add CHLA + CHLA_QC (aggregated)
    validated_df['CHLA'] = df_qc['CHLA']
    _log.info("Aggregating CHLA QC flags...")
    chla_qc_columns = [
        'CHLA_Range_QC',
        'CHLA_Na_QC',
        'CHLA_Sensor_QC',
        'CHLA_Spike_QC',
        'CHLA_Surface_QC',
        'CHLA_Stuck_QC'
    ]
    
    # Apply aggregation function (vectorized)
    validated_df['CHLA_QC'] = df_qc.apply(
        lambda row: aggregate_qc_flags(row, chla_qc_columns),
        axis=1
    )
    
    _log.info(f"Added CHLA + CHLA_QC - Flag distribution:")
    _log.info(f"  {validated_df['CHLA_QC'].value_counts().to_dict()}")
    
    # Step 7: Add TURB + TURB_QC (aggregated)
    validated_df['TURB'] = df_qc['TURB']
    _log.info("Aggregating TURB QC flags...")
    turb_qc_columns = [
        'TURB_Range_QC',
        'TURB_Na_QC',
        'TURB_Sensor_QC',
        'TURB_Spike_QC',
        'TURB_Surface_QC',
        'TURB_Stuck_QC'
    ]
    
    # Apply aggregation function
    validated_df['TURB_QC'] = df_qc.apply(
        lambda row: aggregate_qc_flags(row, turb_qc_columns),
        axis=1
    )
    
    _log.info(f"Added TURB + TURB_QC - Flag distribution:")
    _log.info(f"  {validated_df['TURB_QC'].value_counts().to_dict()}")
    
    # Step 8: Add DOXY + DOXY_QC (aggregated)
    validated_df['DOXY'] = df_qc['DOXY']
    _log.info("Aggregating DOXY QC flags...")
    doxy_qc_columns = [
        'DOXY_Range_QC',
        'DOXY_Na_QC',
        'DOXY_Sensor_QC',
        'DOXY_Spike_QC',
        'DOXY_Gradient_QC',
        'DOXY_Stuck_QC'
    ]
    
    # Apply aggregation function
    validated_df['DOXY_QC'] = df_qc.apply(
        lambda row: aggregate_qc_flags(row, doxy_qc_columns),
        axis=1
    )
    
    _log.info(f"Added DOXY + DOXY_QC - Flag distribution:")
    _log.info(f"  {validated_df['DOXY_QC'].value_counts().to_dict()}")
    
    # Step 9: Add PSAL + PSAL_QC (aggregated)
    validated_df['PSAL'] = df_qc['PSAL']
    _log.info("Aggregating PSAL QC flags...")
    psal_qc_columns = [
        'PSAL_Range_QC',
        'PSAL_Spike_QC',
        'PSAL_Density_QC'
    ]
    
    # Apply aggregation function
    validated_df['PSAL_QC'] = df_qc.apply(
        lambda row: aggregate_qc_flags(row, psal_qc_columns),
        axis=1
    )
    
    _log.info(f"Added PSAL + PSAL_QC - Flag distribution:")
    _log.info(f"  {validated_df['PSAL_QC'].value_counts().to_dict()}")
    
    # Step 10: Add PRES + PRES_QC (aggregated)
    validated_df['PRES'] = df_qc['PRES']
    _log.info("Aggregating PRES QC flags...")
    pres_qc_columns = [
        'PRES_Max_QC',
        'PRES_Density_QC',
        'PRES_Increasing_QC'
    ]
    
    # Apply aggregation function
    validated_df['PRES_QC'] = df_qc.apply(
        lambda row: aggregate_qc_flags(row, pres_qc_columns),
        axis=1
    )
    
    _log.info(f"Added PRES + PRES_QC - Flag distribution:")
    _log.info(f"  {validated_df['PRES_QC'].value_counts().to_dict()}")
    
    # Step 11: Add LAND_QC flag (direct copy, no data column)
    validated_df['LAND_QC'] = df_qc['LAND_QC']
    
    _log.info(f"Added LAND_QC column - Flag distribution:")
    _log.info(f"  {validated_df['LAND_QC'].value_counts().to_dict()}")
    
    # Step 12: Add VELOCITY + VELOCITY_QC (direct copy)
    validated_df['VELOCITY'] = df_qc['VELOCITY']
    validated_df['VELOCITY_QC'] = df_qc['VELOCITY_QC']
    
    _log.info(f"Added VELOCITY + VELOCITY_QC - Flag distribution:")
    _log.info(f"  {validated_df['VELOCITY_QC'].value_counts().to_dict()}")
    
    return validated_df


def export_validated_csv(validated_df: pd.DataFrame, output_path: str):
    """Export the validated dataset to CSV.
    
    Args:
        validated_df: The validated DataFrame
        output_path: Path where to save the CSV file
    """
    # Create output directory if it doesn't exist
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # Export to CSV with 'null' for missing values (consistent with qc_variables.py)
    validated_df.to_csv(output_path, index=False, na_rep='null')
    
    _log.info(f"Exported validated dataset to: {output_path}")
    _log.info(f"Total rows: {len(validated_df)}")
    _log.info(f"Total columns: {len(validated_df.columns)}")


def main():
    """Main execution function."""
    _log.info("="*60)
    _log.info("QC VALIDATED DATASET GENERATOR - STEP 11 (FINAL)")
    _log.info("="*60)
    
    # Define paths
    input_csv = 'output/analysis/seaexplorer_qc_variables.csv'
    output_csv = 'output/analysis/QC_validated.csv'
    
    # Check if input file exists
    if not os.path.exists(input_csv):
        _log.error(f"Input file not found: {input_csv}")
        _log.error("Please run qc_variables.py first to generate the QC CSV file.")
        return
    
    # Step 1: Load the QC CSV
    qc_data = load_qc_csv(input_csv)
    
    # Step 2-11: Create validated dataset with aggregated QC flags
    validated_data = create_validated_dataset(qc_data)
    
    # Step 12: Export to CSV
    export_validated_csv(validated_data, output_csv)
    
    _log.info("="*60)
    _log.info("ALL STEPS COMPLETED: QC_validated.csv ready!")
    _log.info("="*60)


if __name__ == '__main__':
    main()
