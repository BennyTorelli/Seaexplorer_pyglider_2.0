# Best Practices for Quality Control of SeaExplorer Glider Data

**Journal:** Frontiers in Marine Science  
**Section:** Best Practice in Ocean Observing  
**Authors:** [Your Name/Institution]  
**Repository:** https://github.com/BennyTorelli/Seaexplorer_pyglider  
**Version:** 2.0  
**Last Updated:** October 2025

---

## Abstract

Autonomous underwater gliders have become indispensable platforms for sustained ocean observation, generating high-resolution, multi-disciplinary datasets. The SeaExplorer glider, in particular, offers a unique combination of endurance, payload capacity, and maneuverability. However, the value of the data it collects is contingent upon rigorous, transparent, and reproducible Quality Control (QC) procedures. This document outlines a comprehensive, 12-tier QC framework designed specifically for SeaExplorer data, integrating established community standards (e.g., QARTOD) with novel methodologies developed to address platform-specific challenges. We present a detailed, test-by-test description of the framework, including the scientific rationale, implementation logic, and the corresponding Python code. The proposed workflow enhances data integrity by identifying and flagging anomalies related to sensor performance, environmental contamination, and geophysical inconsistencies. Adherence to these best practices is critical for ensuring that glider data is robust, interoperable, and fit for scientific analysis, publication, and submission to global data repositories.

---

## 1. Introduction: The Critical Role of Quality Control in Glider Oceanography

Autonomous underwater vehicles, particularly buoyancy-driven gliders, have revolutionized our ability to sample the marine environment. These platforms can survey vast oceanic regions for extended periods (weeks to months), collecting high-resolution data on physical, biogeochemical, and ecological variables at a fraction of the cost of traditional ship-based methods (Rudnick, 2016). The SeaExplorer glider, developed by ALSEAMAR, is a state-of-the-art vehicle characterized by its high payload capacity, low energy consumption, and advanced navigation capabilities, making it an ideal tool for multi-disciplinary oceanographic research.

However, the very nature of autonomous, long-duration deployments exposes the onboard sensors to a wide range of potential issues, including biofouling, calibration drift, electronic noise, and environmental contamination (e.g., surface bubbles, sediment resuspension). These factors can introduce errors and uncertainties that, if left unaddressed, can corrupt scientific analyses, lead to erroneous conclusions, and undermine the value of the collected data.

Therefore, a systematic and robust Quality Control (QC) process is not merely a procedural step but a fundamental component of the data life cycle. The primary objectives of this QC framework are to:

1.  **Ensure Data Integrity:** Objectively identify and flag suspect or erroneous data points, ensuring that scientific conclusions are based on reliable measurements.
2.  **Enhance Interoperability:** Standardize data quality assessment according to community-accepted conventions (e.g., IOOS QARTOD, Argo), facilitating data sharing and integration into larger ocean observing systems.
3.  **Provide Transparency:** Document every QC test and its outcome, allowing end-users to understand the quality of each data point and make informed decisions about its use.
4.  **Diagnose Platform/Sensor Health:** Use QC flags as a diagnostic tool to identify sensor malfunctions, calibration issues, or platform-specific problems that may require intervention.
5.  **Automate Data Processing:** Enable the development of automated, reproducible data processing pipelines that are essential for handling the large volumes of data generated by modern glider fleets.

This document presents a best-practice QC framework composed of 12 distinct tiers, which has been successfully applied to SeaExplorer missions in the Canary Islands region. It combines established oceanographic tests with innovative methods tailored to the specific error modes of glider-based sensors. Each test is described in detail, providing the scientific justification, implementation logic, and the open-source Python code used in our pipeline, thereby offering a complete and reproducible workflow for the broader scientific community.

**References:**
- Rudnick, D. L. (2016). Ocean research enabled by underwater gliders. *Annual Review of Marine Science*, 8, 519-541.

---

## 2. QC Framework Overview

Our implementation uses **12 independent QC tiers**, each testing different aspects of the data. This multi-tiered approach ensures that a wide range of potential errors are captured, from simple sensor range violations to complex, context-dependent anomalies like density inversions or bio-optical spikes.

| Tier | Name | Purpose | Test Count | Flag Columns |
|------|------|---------|-----------|--------------|
| 1 | **Temporal Validity** | Verify date/time integrity | 1 | `Date_QC` |
| 2 | **Geographic Position** | Check spatial bounds and land collision | 2 | `Location_QC`, `LAND_QC` |
| 3 | **Missing Values** | Identify and flag `NaN`/null data points | 5 | `{VAR}_Na_QC` |
| 4 | **Gross Range (Sensor)** | Check against sensor's physical limits | 5 | `{VAR}_Sensor_QC` |
| 5 | **Climatological Range** | Verify data against regional oceanographic norms | 6 | `{VAR}_Range_QC` |
| 6 | **Spike Detection (Physical)** | Identify abrupt, localized anomalies in T, S, O₂ | 3 | `TEMP_Spike_QC`, `PSAL_Spike_QC`, `DOXY_Spike_QC` |
| 7 | **Spike Detection (Bio-Optical)** | Identify negative spikes in CHLA, TURB | 2 | `CHLA_Spike_QC`, `TURB_Spike_QC` |
| 8 | **Surface Contamination** | Flag near-surface bio-optical data prone to artifacts | 2 | `CHLA_Surface_QC`, `TURB_Surface_QC` |
| 9 | **Vertical Gradient (DOXY)** | Detect excessive, unrealistic vertical changes in oxygen | 1 | `DOXY_Gradient_QC` |
| 10 | **Pressure Integrity** | Verify pressure sensor limits and behavior | 2 | `PRES_Max_QC`, `PRES_Increasing_QC` |
| 11 | **Density Inversion** | Detect hydrostatically unstable water column conditions | 3 | `TEMP_Density_QC`, `PRES_Density_QC`, `PSAL_Density_QC` |
| 12 | **Stuck Sensor** | Identify sensor failures resulting in constant values | 5 | `{VAR}_Stuck_QC` |

**Total QC Flags:** 37 flags are generated and exported to a comprehensive CSV file for analysis.

**Innovative Tiers:** Tiers 6, 7, 8, 9, 10, 11, and 12 employ novel or advanced methodologies specifically developed or adapted for autonomous glider platforms, as detailed in Section 4.

---

## 3. QC Flag Definitions

To ensure interoperability with global data systems, we use a simplified version of the **IODE/ARGO QC flag scheme**. This system is machine-readable and provides clear, actionable information about data quality.

| Flag | Name | Description | Interpretation & Action |
|------|------|-------------|----------------|
| **1** | **GOOD** | The data point has passed all relevant QC tests. | Data are considered reliable and fit for scientific use without reservation. |
| **4** | **BAD** | The data point has failed at least one critical QC test. | Data are considered erroneous, unrealistic, or highly suspect. **Action:** Exclude from analysis. |
| **9** | **MISSING** | The data point was not recorded or is unavailable (`NaN`). | Represents a data gap. This is not an error but an absence of information. |
| **0** | **NOT EVALUATED** | The data point was not subjected to a specific QC test. | This occurs for edge points in a profile, or if prerequisite data (e.g., pressure) is missing. It does not imply the data is bad, only that a test was not performed. |

**Flag Aggregation:**
A data point is considered **GOOD (1)** only if it passes *all* applicable tests. If it fails even a single test, its overall quality is designated as **BAD (4)**. This conservative approach ensures that only the highest-quality data are used in subsequent analyses.

---

## 4. Detailed QC Test Descriptions

This section provides a comprehensive description of each of the 12 QC tiers, including the scientific rationale, implementation details, and the corresponding Python code.

### 4.1 Tier 1: Temporal Validity Test (`Date_QC`)

**Scientific Rationale:**
The integrity of the timestamp associated with each measurement is fundamental to all subsequent analyses. Errors in the time record can arise from GPS rollover events, clock drift, or data corruption during transmission. This test ensures that all timestamps are plausible and fall within an expected historical and operational range.

**Implementation:**
The test flags any timestamp that is either in the future or predates the modern era of oceanographic glider operations (est. 1950).

```python
# From: scripts/qc_variables.py

def range_qc_time(ds: xr.Dataset, time_coord: str = 'TIME') -> xr.Dataset:
    # ...
    min_time = pd.Timestamp('1950-01-01') # Note: A more specific '2000-01-01' is better practice
    max_time = pd.Timestamp(datetime.now())
    
    time_values = pd.to_datetime(ds[time_var].values)
    flags = np.full(time_values.shape, np.nan, dtype=float)
    
    valid_mask = pd.notna(time_values)
    if valid_mask.any():
        valid_times = time_values[valid_mask]
        pass_mask = (valid_times >= min_time) & (valid_times <= max_time)
        flags[valid_mask] = np.where(pass_mask, 1, 4)
    # ...
```

**Flagging Criteria:**
- **`1` (GOOD):** The timestamp is between the beginning of the instrument era and the present moment.
- **`4` (BAD):** The timestamp is outside this range or is not a valid date.

### 4.2 Tier 2: Geographic Position Tests

#### 4.2.1 Gross Location Test (`Location_QC`)

**Scientific Rationale:**
This test serves as a coarse filter to identify significant position errors that could result from GPS malfunctions or failures in the glider's dead-reckoning navigation system. It ensures that all reported positions fall within a predefined, generous bounding box for the mission area.

**Implementation:**
The code checks if latitude and longitude coordinates are within the expected operational area for the La Palma mission.

```python
# From: scripts/qc_variables.py

# This logic is part of the export_qc_to_csv function
# A combined Location_QC is created from individual LAT/LON QC checks.
# The individual checks are performed by:
range_qc_latitude(ds) # Checks for -90 to 90
range_qc_longitude(ds) # Checks for -180 to 180
# A mission-specific check would be more robust.
```

**Flagging Criteria:**
- **`1` (GOOD):** The (lat, lon) position is within the valid global range.
- **`4` (BAD):** The position is outside the valid global range or coordinates are missing.

#### 4.2.2 Coastal Proximity Test (`LAND_QC`)

**Scientific Rationale:**
A glider is an open-ocean platform and cannot physically operate on land. A reported position located within a landmass is unequivocally an error, typically resulting from a faulty GPS fix. This test provides a high-fidelity check by comparing each data point's coordinates against a detailed coastline polygon. This is a critical test for missions near coastal areas.

**Implementation:**
This test uses the `shapely` library to perform a point-in-polygon analysis. Each (lon, lat) point is checked for containment within a high-resolution polygon representing the island of La Palma.

```python
# From: scripts/qc_variables.py

# Load La Palma island polygon coordinates from a pre-processed JSON file
polygon_file = 'config/shapefiles/LaPalmaDissolve_coords.json'
with open(polygon_file, 'r') as f:
    coords_list = json.load(f)
lapalma_polygon = Polygon(coords_list[0])

# Extract latitude and longitude arrays
lat_arr = ds['LATITUDE'].values
lon_arr = ds['LONGITUDE'].values

# Initialize LAND_QC array
land_qc = np.full(len(lat_arr), 9, dtype=np.int8) # Default to 9 (MISSING)

# Check each point
for i in range(len(lat_arr)):
    if not (np.isnan(lat_arr[i]) or np.isnan(lon_arr[i])):
        point = Point(lon_arr[i], lat_arr[i])
        if lapalma_polygon.contains(point):
            land_qc[i] = 4  # BAD - Point is on land
        else:
            land_qc[i] = 1  # GOOD - Point is in the ocean
```

**Flagging Criteria:**
- **`1` (GOOD):** The glider's position is located in the ocean.
- **`4` (BAD):** The glider's position is located inside the land polygon.
- **`9` (MISSING):** The latitude or longitude coordinate is not available.

### 4.3 Tier 3: Missing Value Test (`{VAR}_Na_QC`)

**Scientific Rationale:**
Missing data points (`NaN`, Not-a-Number) are common in glider datasets. They can result from sensor dropouts, differences in sampling frequencies between instruments, or data transmission failures. While not an "error" in the traditional sense, it is crucial to explicitly identify and flag these gaps. This test ensures that any missing value is flagged as `9`, clearly distinguishing it from valid data (`1`) or bad data (`4`).

**Implementation:**
This simple but essential test iterates through each core variable and flags any `NaN` values.

```python
# From: scripts/qc_variables.py

# This logic is applied to TEMP, CNDC, DOXY, CHLA, and TURB
na_qc_vars = ['TEMP', 'CNDC', 'DOXY', 'CHLA', 'TURB']
for var in na_qc_vars:
    na_qc_col = f'{var}_Na_QC'
    if var in compact.columns:
        # Flag 1 if the value is present (not NaN), 9 if it is missing (NaN)
        compact[na_qc_col] = compact[var].notna().astype(int).replace({1: 1, 0: 9})
    else:
        compact[na_qc_col] = 0 # Not evaluated if the variable is absent
```

**Flagging Criteria:**
- **`1` (GOOD):** A valid, non-`NaN` value is present.
- **`9` (MISSING):** The data point is `NaN`.

### 4.4 Tier 4: Sensor Physical Limits Test (`{VAR}_Sensor_QC`)

**Scientific Rationale:**
Every sensor has a defined physical measurement range specified by the manufacturer. Any value reported outside this range is physically impossible for the sensor to have measured and indicates a critical failure, such as a corrupted data stream or a fundamental electronics malfunction. This test compares each data point against these hard-coded manufacturer limits.

**Implementation:**
A dedicated range check is performed for each core variable using the sensor's specific operational limits. The example below is for the SBE 41CP temperature sensor.

```python
# From: scripts/qc_variables.py

# Example for Temperature (SBE 41CP Sensor)
temp_var = 'TEMP'
temp_sensor_min = -5.0
temp_sensor_max = 42.0
ds_temp_sensor = range_qc_variable(ds, temp_var, temp_sensor_min, temp_sensor_max)

# The generic `range_qc_variable` function applies the logic:
def range_qc_variable(ds: xr.Dataset, varname: str, valid_min: float, valid_max: float) -> xr.Dataset:
    data = ds[varname].values
    flags = np.zeros(data.shape, dtype=float)
    finite_mask = np.isfinite(data)
    if finite_mask.any():
        vals = data[finite_mask]
        pass_mask = (vals >= valid_min) & (vals <= valid_max)
        # Flag 1 (GOOD) if in range, 4 (BAD) if out of range
        flags[finite_mask] = np.where(pass_mask, 1, 4)
    # ... (rest of function)
```

**Flagging Criteria & Sensor Ranges:**
- **`1` (GOOD):** Value is within the sensor's physical range.
- **`4` (BAD):** Value is outside the sensor's physical range.
- **`0` (NOT EVALUATED):** Data point is `NaN`.

| Variable | Sensor | Physical Range | Units |
|----------|--------|----------------|-------|
| **TEMP** | SBE 41CP | -5.0 to 42.0 | °C |
| **CNDC** | SBE 41CP | 0.0 to 8.5 | S/m |
| **DOXY** | Aanderaa Optode | 0.0 to 500.0 | µmol/L |
| **CHLA** | WET Labs ECO | 0.0 to 50.0 | mg/m³ |
| **TURB** | WET Labs ECO | 0.0 to 25.0 | NTU |

### 4.5 Tier 5: Climatological Range Test (`{VAR}_Range_QC`)

**Scientific Rationale:**
While the sensor limits test catches impossible values, the climatological range test identifies *implausible* values. Based on historical data for a specific oceanographic region (in this case, the Canary Islands), we can define a much narrower, expected range for each variable. A value outside this climatological envelope, while perhaps physically possible for the sensor to read, is highly unlikely to be correct for the given location and time of year. It often indicates sensor drift or a temporary environmental anomaly that requires scrutiny.

**Implementation:**
This test is identical in structure to the sensor limits test but uses stricter, region-specific thresholds defined in the `QC_RANGES_LAPALMA` dictionary.

```python
# From: scripts/qc_variables.py

# QC Range constants for La Palma zone
QC_RANGES_LAPALMA = {
    'TEMP': {'min': 5.0, 'max': 30.0, 'unit': '°C'},
    'PSAL': {'min': 33.0, 'max': 38.0, 'unit': 'PSU'},
    'CNDC': {'min': 0.0, 'max': 7.0, 'unit': 'S/m'},
    'DOXY': {'min': 110.0, 'max': 250.0, 'unit': 'µmol/L'},
    'CHLA': {'min': 0.0, 'max': 42.0, 'unit': 'mg/m³'},
    'TURB': {'min': 0.0, 'max': 5.0, 'unit': 'NTU'},
}

# Example for Conductivity
cndc_min = QC_RANGES_LAPALMA['CNDC']['min']
cndc_max = QC_RANGES_LAPALMA['CNDC']['max']
ds = range_qc_variable(ds, 'CNDC', cndc_min, cndc_max)
# (The same `range_qc_variable` function is called for each variable)
```

**Flagging Criteria:**
- **`1` (GOOD):** Value is within the expected climatological range for La Palma.
- **`4` (BAD):** Value is outside the climatological range.
- **`0` (NOT EVALUATED):** Data point is `NaN`.

### 4.6 Tier 6: Spike Detection (Physical Variables)

**Scientific Rationale:**
Spikes are isolated data points that are clearly anomalous with respect to their immediate neighbors. They typically result from electronic noise, transient environmental contamination (e.g., a particle briefly passing the sensor), or data transmission errors. This test is designed to identify such outliers in the physical data streams (Temperature, Salinity, Oxygen). The algorithm is adapted from the QARTOD spike test and uses a 3-point running window to evaluate the "local relief" of a data point. A point is flagged as a spike if its value represents an abrupt, non-physical deviation from the local trend.

**Implementation:**
The core of the test calculates a spike metric, `VR`, which is the difference between the point's deviation from the midpoint of its neighbors and half the range of its neighbors. This metric is compared against a depth-dependent threshold, as variability is naturally higher in the upper ocean.

```python
# From: scripts/qc_variables.py

def spike_qc_generic(values, pressure, r1_threshold, r2_threshold, var_name):
    n = len(values)
    qc_flags = np.full(n, 0, dtype=int) # Initialize with 0 (not evaluated)
    
    for i in range(1, n - 1): # Loop through observations (skip first and last)
        V1, V2, V3 = values[i-1], values[i], values[i+1]
        P = pressure[i]
        
        if np.isnan(V1) or np.isnan(V2) or np.isnan(V3) or np.isnan(P):
            qc_flags[i] = 0 # Not evaluated if data is missing
            continue
        
        # Calculate VR (spike metric)
        VR = abs(V2 - (V3 + V1) / 2.0) - abs((V3 - V1) / 2.0)
        
        # Determine threshold based on pressure
        threshold = r1_threshold if P < 500.0 else r2_threshold
        
        # Assign flag
        qc_flags[i] = 4 if VR >= threshold else 1
    
    return qc_flags

# Example application for Temperature
compact['TEMP_Spike_QC'] = spike_qc_generic(
    compact['TEMP'].values, compact['PRES'].values,
    r1_threshold=6.0,   # °C for PRES < 500 dbar
    r2_threshold=2.0,   # °C for PRES >= 500 dbar
    var_name='TEMP'
)
```

**Flagging Criteria & Thresholds:**
- **`1` (GOOD):** The point is consistent with its neighbors.
- **`4` (BAD):** The point is an anomalous spike (`VR >= threshold`).
- **`0` (NOT EVALUATED):** The point is at the start/end of a profile or has missing neighbors.

| Variable | Shallow Threshold (<500 dbar) | Deep Threshold (≥500 dbar) | Units |
|----------|-------------------------------|----------------------------|---------|
| **TEMP** | 6.0 | 2.0 | °C |
| **PSAL** | 0.9 | 0.3 | PSU |
| **DOXY** | 50.0 | 25.0 | µmol/kg |

### 4.7 Tier 7: Spike Detection (Bio-Optical Variables)

**Scientific Rationale:**
This is a **novel methodology** developed for fluorescence-based sensors (Chlorophyll-a, Turbidity), which have different error characteristics than physical sensors. Bio-optical measurements are prone to transient *negative* spikes caused by air bubbles, particle aggregation, or brief sensor blockages. A standard bidirectional spike test is less effective. This test uses a more robust 5-point median-based approach to specifically target these negative anomalies. The residual (`RES`) of a point relative to the median of its neighbors is compared against a dynamic threshold derived from the data itself.

**Implementation:**
The algorithm calculates the residual for each point within a flexible 5-point window (which can skip over `NaN` values). The flagging threshold is dynamically set to twice the 10th percentile of all calculated residuals, making it adaptive to the baseline noise level of the sensor and the optical conditions of the water.

```python
# From: scripts/qc_variables.py

def spike_qc_negative_5point(values, var_name):
    n = len(values)
    qc_flags = np.full(n, 0, dtype=int)
    res_list = []
    res_indices = []
    
    for i in range(2, n - 2): # Skip first 2 and last 2
        V2 = values[i]
        if np.isnan(V2):
            qc_flags[i] = 0
            continue
        
        # Find 2 valid neighbors before and 2 after, skipping NaNs
        before_vals, after_vals = find_valid_neighbors(i, values, n_before=2, n_after=2)
        
        if before_vals is None or after_vals is None:
            qc_flags[i] = 0
            continue
        
        # Calculate RES = V2 - median(window)
        window_values = before_vals + [V2] + after_vals
        median_val = np.median(window_values)
        res = V2 - median_val
        res_list.append(res)
        res_indices.append(i)
    
    if not res_list: return qc_flags
    
    # Dynamic threshold: 2 * 10th percentile of residuals
    threshold = 2.0 * np.percentile(res_list, 10)
    
    # Assign flags
    for idx, res in zip(res_indices, res_list):
        qc_flags[idx] = 4 if res < threshold else 1
        
    return qc_flags
```

**Flagging Criteria:**
- **`1` (GOOD):** The point is consistent with the local median.
- **`4` (BAD):** The point is a significant negative anomaly (`RES < threshold`).
- **`0` (NOT EVALUATED):** The point is near the profile edge or has insufficient valid neighbors.

### 4.8 Tier 8: Surface Contamination Test (Bio-Optical)

**Scientific Rationale:**
This is another **novel test** for bio-optical data. The top few meters of the ocean are a challenging environment for optical sensors. Measurements can be contaminated by (1) air bubbles entrained as the glider submerges, (2) non-photochemical quenching (NPQ), where high sunlight intensity artificially suppresses the chlorophyll fluorescence signal, and (3) interactions with the sea surface microlayer. This test applies a simple but effective prophylactic measure: it flags all bio-optical data collected at very shallow depths as potentially unreliable.

**Implementation:**
The test flags all `CHLA` and `TURB` measurements where the corresponding pressure reading is less than or equal to 5 dbar. This effectively excludes the top ~5 meters of the water column, a common practice in BGC-Argo float data processing.

```python
# From: scripts/qc_variables.py

# Logic for CHLA Surface QC (identical for TURB)
if 'CHLA' in compact.columns and 'PRES' in compact.columns:
    pres_vals = compact['PRES'].values
    chla_vals = compact['CHLA'].values
    n = len(pres_vals)
    chla_surface_q = np.zeros(n, dtype=int)
    
    for i in range(n):
        p = pres_vals[i]
        if np.isnan(p) or np.isnan(chla_vals[i]):
            chla_surface_q[i] = 0 # Not evaluated
        else:
            # Flag 4 (BAD) if pressure <= 5 dbar, else 1 (GOOD)
            chla_surface_q[i] = 4 if p <= 5.0 else 1
            
    compact['CHLA_Surface_QC'] = chla_surface_q
```

**Flagging Criteria:**
- **`1` (GOOD):** The measurement was taken at a pressure greater than 5 dbar.
- **`4` (BAD):** The measurement was taken at a pressure of 5 dbar or less.
- **`0` (NOT EVALUATED):** Pressure or the variable itself is missing.

### 4.9 Tier 9: Vertical Gradient Test (DOXY)

**Scientific Rationale:**
This test is complementary to the spike test for dissolved oxygen. While the spike test identifies isolated outliers, the gradient test identifies unrealistically sharp, but potentially sustained, changes in the vertical oxygen profile. Such features can indicate sensor response time issues, calibration problems, or passage through a fine-scale feature that warrants closer inspection. It uses a similar 3-point window but focuses on the magnitude of the deviation from the local linear trend.

**Implementation:**
The test calculates the absolute difference between a point (`V2`) and the mean of its neighbors (`V1`, `V3`). This difference is compared against a depth-dependent threshold. The neighbor-finding logic is flexible, allowing it to skip `NaN` values to find the nearest valid points for comparison.

```python
# From: scripts/qc_variables.py

def doxy_gradient_qc_3point(doxy_values, pressure_values):
    n = len(doxy_values)
    qc_flags = np.zeros(n, dtype=int)
    
    for i in range(1, n - 1):
        V2, P = doxy_values[i], pressure_values[i]
        if np.isnan(V2) or np.isnan(P):
            qc_flags[i] = 0
            continue
        
        # Find nearest valid neighbors
        V1 = find_valid_neighbor_before(doxy_values, i)
        V3 = find_valid_neighbor_after(doxy_values, i)
        
        if V1 is None or V3 is None:
            qc_flags[i] = 0
            continue
        
        # Calculate gradient metric VR
        VR = abs(V2 - (V3 + V1) / 2.0)
        
        # Depth-dependent threshold
        threshold = 50.0 if P < 500.0 else 25.0
        
        qc_flags[i] = 4 if VR >= threshold else 1
        
    return qc_flags
```

**Flagging Criteria:**
- **`1` (GOOD):** The vertical gradient is within expected limits.
- **`4` (BAD):** The vertical gradient is excessive (`VR >= threshold`).
- **`0` (NOT EVALUATED):** The point is near an edge or has insufficient neighbors.

### 4.10 Tier 10: Pressure Integrity Tests

#### 4.10.1 Maximum Pressure Test (`PRES_Max_QC`)

**Scientific Rationale:**
The SeaExplorer glider has a maximum operational depth rating, typically 1000 meters. The pressure sensor housing has a crush depth that should never be exceeded. This test acts as a critical safety check, flagging any pressure reading that surpasses the glider's certified maximum depth plus a small margin.

**Implementation:**
A simple range check is applied to the pressure data, flagging any value greater than 1100 dbar (1000 dbar rating + 10% safety margin).

```python
# From: scripts/qc_variables.py

if 'PRES' in compact.columns:
    pres_vals = compact['PRES'].values
    n = len(pres_vals)
    pres_max_q = np.zeros(n, dtype=int)
    for i in range(n):
        p = pres_vals[i]
        if np.isnan(p):
            pres_max_q[i] = 0 # Not evaluated
        else:
            # Flag 1 if within limit, 4 if exceeding limit
            pres_max_q[i] = 1 if p <= 1100.0 else 4
    compact['PRES_Max_QC'] = pres_max_q
```

**Flagging Criteria:**
- **`1` (GOOD):** Pressure is less than or equal to 1100 dbar.
- **`4` (BAD):** Pressure exceeds 1100 dbar.
- **`0` (NOT EVALUATED):** Pressure data is `NaN`.

#### 4.10.2 Pressure Increasing Test (`PRES_Increasing_QC`)

**Scientific Rationale:**
A functioning pressure sensor on a moving glider should exhibit constantly changing values (except perhaps at the very apex of a profile). If the pressure reading remains identical for consecutive measurements, it suggests the sensor may be "stuck" or failing. This test flags any instance where the pressure does not change between one measurement and the next.

**Implementation:**
The test compares each pressure value (`v2`) with the preceding one (`v1`). If they are identical, the point is flagged.

```python
# From: scripts/qc_variables.py

if 'PRES' in compact.columns:
    pres_vals = compact['PRES'].values
    n = len(pres_vals)
    pres_inc_q = np.zeros(n, dtype=int)
    for i in range(1, n): # Start from the second point
        v1, v2 = pres_vals[i-1], pres_vals[i]
        if np.isnan(v1) or np.isnan(v2):
            pres_inc_q[i] = 0 # Not evaluated
        else:
            # Flag 1 if pressure changes, 4 if it is stuck
            pres_inc_q[i] = 1 if v2 != v1 else 4
    compact['PRES_Increasing_QC'] = pres_inc_q
```

**Flagging Criteria:**
- **`1` (GOOD):** The pressure value has changed from the previous measurement.
- **`4` (BAD):** The pressure value is identical to the previous measurement.
- **`0` (NOT EVALUATED):** The first point in a series, or if data is `NaN`.

### 4.11 Tier 11: Density Inversion Test

**Scientific Rationale:**
In a stable ocean, water density should increase with depth. A "density inversion," where denser water overlies lighter water, is a hydrostatically unstable condition. While small, transient inversions can occur due to processes like double diffusion, large and persistent inversions in glider data are almost always indicative of a sensor problem, typically with the conductivity cell (leading to incorrect salinity). This test uses the robust TEOS-10 Gibbs Seawater (GSW) library to calculate potential density and flags any significant inversions between consecutive data points.

**Implementation:**
The code calculates potential density (`pot_rho_t_exact`) for pairs of consecutive points at a common reference pressure. It then checks if the density of the deeper point is significantly less than that of the shallower point.

```python
# From: scripts/qc_variables.py
import gsw

# ... (looping through consecutive points i and i+1)
# Calculate reference pressure
pref = (pres_i + pres_i1) / 2.0

# Calculate Absolute Salinity from Practical Salinity
sa_i = gsw.SA_from_SP(psal_i, pres_i, lon_i, lat_i)
sa_i1 = gsw.SA_from_SP(psal_i1, pres_i1, lon_i1, lat_i1)

# Calculate potential density at the reference pressure
rho_i = gsw.pot_rho_t_exact(sa_i, temp_i, pres_i, pref)
rho_i1 = gsw.pot_rho_t_exact(sa_i1, temp_i1, pres_i1, pref)

# Check for inversions (threshold = 0.03 kg/m³)
threshold = 0.03
# This logic needs to account for upcast vs downcast
# Simplified logic shown:
if (pres_i < pres_i1) and ((rho_i1 - rho_i) < -threshold): # Downcast
    # Density inversion detected
    temp_density_q[i] = 4
    #...
elif (pres_i > pres_i1) and ((rho_i - rho_i1) < -threshold): # Upcast
    # Density inversion detected
    temp_density_q[i] = 4
    #...
else:
    # No significant inversion
    temp_density_q[i] = 1
    # ...
```

**Flagging Criteria:**
- **`1` (GOOD):** The density gradient is stable or the inversion is negligible (`< 0.03 kg/m³`).
- **`4` (BAD):** A significant density inversion (`>= 0.03 kg/m³`) is detected. The `TEMP`, `PSAL`, and `PRES` variables for that point are all flagged.
- **`0` (NOT EVALUATED):** Missing data prevents calculation.

### 4.12 Tier 12: Stuck Sensor Test

**Scientific Rationale:**
This test is a more sophisticated version of the `PRES_Increasing_QC` test, applied to all core variables. A sensor that reports an identical value for an entire profile segment (i.e., a full downcast or upcast) is almost certainly malfunctioning or "stuck." This test first identifies individual profile segments based on the direction of pressure change, and then checks if all non-`NaN` values within that segment are identical for a given variable.

**Implementation:**
The code first parses the data into segments of continuous ascent or descent. Then, for each segment and for each variable, it checks if the set of valid (non-`NaN`) values contains more than one unique value. If not, the entire segment is flagged as bad for that variable.

```python
# From: scripts/qc_variables.py

# First, identify profile segments based on pressure changes
# ... (code to create segment_id for each point) ...

# Then, apply stuck values test to each variable
stuck_vars = ['TEMP', 'CNDC', 'DOXY', 'CHLA', 'TURB']
for var in stuck_vars:
    var_vals = compact[var].values
    stuck_qc = np.zeros(n, dtype=int)
    
    # Process each segment
    for seg_id in np.unique(segment_id):
        if seg_id < 0: continue
        
        seg_mask = segment_id == seg_id
        
        # Get valid (non-NaN) values in this segment
        valid_values = var_vals[seg_mask][~np.isnan(var_vals[seg_mask])]
        
        if len(valid_values) < 2: # Need at least 2 points to check for "stuck"
            stuck_qc[seg_mask] = 1 # Not enough data to say it's stuck
            continue
        
        # Check if all valid values are identical
        if np.all(valid_values == valid_values[0]):
            stuck_qc[seg_mask] = 4 # BAD - sensor is stuck
        else:
            stuck_qc[seg_mask] = 1 # GOOD - values vary
            
    compact[f'{var}_Stuck_QC'] = stuck_qc
```

**Flagging Criteria:**
- **`1` (GOOD):** The sensor values vary within a profile segment.
- **`4` (BAD):** All valid sensor values within a profile segment are identical.
- **`0` (NOT EVALUATED):** The segment contains insufficient valid data or is not part of a profile.

---

## 5. Conclusion

The 12-tier Quality Control framework presented here provides a robust, transparent, and reproducible methodology for assessing the quality of SeaExplorer glider data. By combining community-standard tests with novel, platform-specific checks, it ensures a high level of data integrity. The detailed descriptions and open-source code provided in this guide are intended to serve as a best-practice template for the oceanographic community, promoting the generation of high-quality, interoperable glider datasets fit for scientific publication and long-term archiving.
